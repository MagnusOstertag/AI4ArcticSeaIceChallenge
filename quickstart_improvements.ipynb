{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c461fb7-78b9-4201-847e-2e11c8f599ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Quick start guide\n",
    "This notebook serves as an example of how to train a simple model using pytorch and the ready-to-train AI4Arctic challenge dataset. Initially, a dictionary, 'train_options', is set up with relevant options for both the example U-Net Convolutional Neural Network model and the dataloader. Note that the weights of the U-Net will be initialised at random and therefore not deterministic - results will vary for every training run. Two lists (dataset.json and testset.json) include the names of the scenes relevant to training and testing, where the former can be altered if desired. Training data is loaded in parallel using the build-in torch Dataset and Dataloader classes, and works by randomly sampling a scene and performing a random crop to extract a patch. Each batch will then be compiled of X number of these patches with the patch size in the 'train_options'. An obstacle is different grid resolution sizes, which is overcome by upsampling low resolution variables, e.g. AMSR2, ERA5, to match the SAR pixels. A number of batches will be prepared in parallel and stored until use, depending on the number of workers (processes) spawned (this can be changed in 'num_workers' in 'train_options'). The model is trained on a fixed number of steps according to the number of batches in an epoch, defined by the 'epoch_len' parameter, and will run for a total number of epochs depending on the 'epochs' parameter. After each epoch, the model is evaluated. In this example, a random number of scenes are sampled among the training scenes (and removed from the list of training scenes) to act as a validation set used for the evaluation. The model is evaluated with the metrics, and if the current validation attempt is superior to the previous, then the model parameters are stored in the 'best_model' file in the directory.\n",
    "\n",
    "The models are scored on the three sea ice parameters; Sea Ice Concentration (SIC), Stage of Development (SOD) and the Floe size (FLOE) with the $RÂ²$ metric for the SIC, and the weighted F1 metric for the SOD and FLOE. The 3 scores are combined into a single metric by taking the weighted average with SIC and SOD being weighted with 2 and the FLOE with 1.\n",
    "\n",
    "Finally, once you are ready to test your model on the test scenes (without reference data), the 'test_upload' notebook will produce model outputs with your model of choice and save the output as a netCDF file, which can be uploaded to the AI4EO.eu website. The model outputs will be evaluated and then you will receive a score. \n",
    "\n",
    "This quick start notebook is by no means necessary to utilize, and you are more than welcome to develop your own data pipeline. We do however require that the model output is stored in a netcdf file with xarray.dataarrays titled '{scene_name}_{chart}', i.e. 3 charts per scene / file (see how in 'test_upload'). In addition, you are more than welcome to create your own preprocessing scheme to prepare the raw AI4Arctic challenge dataset. However, we ask that the model output is in 80 m pixel spacing (original is 40 m), and that you follow the class numberings from the lookup tables in 'utils' - at least you will be evaluated in this way. Furthermore, we have included a function to convert the polygon_icechart to SIC, SOD and FLOE, you will have to incorporate it yourself.\n",
    "\n",
    "The first cell imports the necessary Python packages, initializes the 'train_options' dictionary, the sample U-Net options, loads the dataset list and select validation scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a8d5a8-674a-42b3-9789-2a04818fa860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Built-in modules -- #\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# -- Environmental variables -- #\n",
    "#os.environ['AI4ARCTIC_DATA'] = ''  # Fill in directory for data location.\n",
    "#os.environ['AI4ARCTIC_ENV'] = ''  # Fill in directory for environment with Ai4Arctic get-started package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c82d24f0-233b-41f9-95ef-af0cc0895800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_options' (dict)\n",
      "Options initialised\n"
     ]
    }
   ],
   "source": [
    "# -- Third-part modules -- #\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import xarray as xr\n",
    "from tqdm.notebook import tqdm  # Progress bar\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# --Proprietary modules -- #\n",
    "from functions_improvements import chart_cbar, r2_metric, f1_metric, compute_metrics  # Functions to calculate metrics and show the relevant chart colorbar.\n",
    "from loaders_improvements import AI4ArcticChallengeDataset, AI4ArcticChallengeTestDataset, get_variable_options  # Custom dataloaders for regular training and validation.\n",
    "from unet_improvements import UNet  # Convolutional Neural Network model\n",
    "from unet_transfer import UNetTrans  # Convolutional Neural Network model with transfer learning\n",
    "from utils import CHARTS, SIC_LOOKUP, SOD_LOOKUP, FLOE_LOOKUP, SCENE_VARIABLES, colour_str\n",
    "\n",
    "train_options = {\n",
    "    'model_codename': 'pizza_trestagioni',  # format: pizza_[toppings]\n",
    "    'development': True, # TOCHANGE\n",
    "\n",
    "    # -- Training options -- #\n",
    "    'path_to_processed_data': os.environ['AI4ARCTIC_DATA'],  # Replace with data directory path.\n",
    "    'path_to_env': '',  # Replace with environmment directory path.\n",
    "    'lr': 0.00005,  # Optimizer learning rate.\n",
    "    'epochs': 40,  # Number of epochs before training stop.\n",
    "    'epoch_len': 500,  # Number of batches for each epoch.\n",
    "    'patch_size': 256, # Size of patches sampled. Used for both Width and Height.\n",
    "    'batch_size': 8,  # Number of patches for each batch.\n",
    "    'loader_upsampling': 'nearest',  # How to upscale low resolution variables to high resolution.\n",
    "    'loss_sic': 'classification', # Loss function for SIC, 'regression' or 'classification'.\n",
    "\n",
    "    # -- Data prepraration lookups and metrics.\n",
    "    'train_variables': SCENE_VARIABLES,  # Contains the relevant variables in the scenes.\n",
    "    'charts': CHARTS,  # Charts to train on.\n",
    "    'n_classes': {  # number of total classes in the reference charts, including the mask.\n",
    "        'SIC': SIC_LOOKUP['n_classes'],\n",
    "        'SOD': SOD_LOOKUP['n_classes'],\n",
    "        'FLOE': FLOE_LOOKUP['n_classes']\n",
    "    },\n",
    "    'pixel_spacing': 80,  # SAR pixel spacing. 80 for the ready-to-train AI4Arctic Challenge dataset.\n",
    "    'train_fill_value': 0,  # Mask value for SAR training data.\n",
    "    'class_fill_values': {  # Mask value for class/reference data.\n",
    "        'SIC': SIC_LOOKUP['mask'],\n",
    "        'SOD': SOD_LOOKUP['mask'],\n",
    "        'FLOE': FLOE_LOOKUP['mask'],\n",
    "    },\n",
    "    'get_metadata': True,  # Flag used in the dataloaders to get metadata.\n",
    "    'resampling': True,  # Whether to resample the training data. Otherwise, the scene is randomly sampled.\n",
    "    'path_to_data': 'misc/',  # Path to the data directory.\n",
    "    'visualize_distribution': True,  # Whether to visualize the difference in distribution between the training, validation and test data.\n",
    "    'difficult_locations':['CentralEast', 'NorthAndCentralEast',],  #  'CentralWest', 'SGRDIEA', 'SGRDIMID', 'SGRDIHA'],  # Locations to oversample as they are more difficult to learn.\n",
    "\n",
    "    # -- Validation options -- #\n",
    "    'chart_metric': {  # Metric functions for each ice parameter and the associated weight.\n",
    "        'SIC': {\n",
    "            'func': r2_metric,\n",
    "            'weight': 2,\n",
    "        },\n",
    "        'SOD': {\n",
    "            'func': f1_metric,\n",
    "            'weight': 2,\n",
    "        },\n",
    "        'FLOE': {\n",
    "            'func': f1_metric,\n",
    "            'weight': 1,\n",
    "        },\n",
    "    },\n",
    "    'num_val_scenes': 10,  # Number of scenes randomly sampled from train_list to use in validation.\n",
    "    'validation_seed': 365,  # Seed used to sample the validation scenes. # TODO: optimize validation seed to better reflect the test distribution!\n",
    "    'seed': 365,  # Seed used for the data loaders.\n",
    "\n",
    "    # -- GPU/cuda options -- #\n",
    "    'gpu_id': 0,  # Index of GPU. In case of multiple GPUs.\n",
    "    'num_workers': 6,  # Number of parallel processes to fetch data.\n",
    "    'num_workers_val': 1,  # Number of parallel processes during validation.\n",
    "\n",
    "    # -- Transfer learning options -- #\n",
    "    'transfer_learning': True, # TOCHANGE # Whether to use transfer learning.\n",
    "    'transfer_model_architecture': {'unet_conv_filters': [16, 32, 32, 32],}, # Dict of the differences in the U-Net options of the model architecture.\n",
    "    'transfer_model_path': 'archive/pizza_marinara',  # Path to the model to transfer from.\n",
    "    \n",
    "    # -- U-Net Options -- # now 3 lvls as in the paper\n",
    "    # DIFF:\n",
    "    # 1. run: 'unet_conv_filters': [16, 32, 32, 32],\n",
    "    'unet_conv_filters': [16, 32, 32, 32, 32, 32],  # Number of filters in the U-Net.\n",
    "    'conv_kernel_size': (3, 3),  # Size of convolutional kernels.\n",
    "    'conv_stride_rate': (1, 1),  # Stride rate of convolutional kernels.\n",
    "    'conv_dilation_rate': (1, 1),  # Dilation rate of convolutional kernels.\n",
    "    'conv_padding': (1, 1),  # Number of padded pixels in convolutional layers.\n",
    "    'conv_padding_style': 'zeros',  # Style of padding.\n",
    "}\n",
    "\n",
    "# change train options in development mode\n",
    "if train_options['development']:\n",
    "    train_options['epochs'] = 2\n",
    "    train_options['epoch_len'] = 2\n",
    "    train_options['batch_size'] = 2\n",
    "    train_options['num_val_scenes'] = 2\n",
    "    train_options['visualize_distribution'] = False\n",
    "    train_options['unet_conv_filters'] = [16, 32, 32, 32]\n",
    "\n",
    "# Get options for variables, amsrenv grid, cropping and upsampling.\n",
    "get_variable_options = get_variable_options(train_options)\n",
    "# To be used in test_upload.\n",
    "%store train_options  \n",
    "\n",
    "# Load training list.\n",
    "with open(train_options['path_to_env'] + 'datalists/dataset.json') as file:\n",
    "    train_options['train_list'] = json.loads(file.read())\n",
    "\n",
    "# Select a random number of validation scenes with the same seed. Feel free to change the seed.et\n",
    "np.random.seed(train_options['validation_seed'])\n",
    "train_options['validate_list'] = np.random.choice(np.array(train_options['train_list']), size=train_options['num_val_scenes'], replace=False)\n",
    "# Remove the validation scenes from the train list.\n",
    "train_options['train_list'] = [scene for scene in train_options['train_list'] if scene not in train_options['validate_list']]\n",
    "\n",
    "# Convert the original scene names to the preprocessed names.\n",
    "train_options['train_list_extendedNames'] = train_options['train_list'].copy()\n",
    "train_options['validate_list_extendedNames'] = train_options['validate_list'].copy()\n",
    "train_options['train_list'] = [file[17:32] + '_' + file[77:80] + '_prep.nc' for file in train_options['train_list']]\n",
    "train_options['validate_list'] = [file[17:32] + '_' + file[77:80] + '_prep.nc' for file in train_options['validate_list']]\n",
    "\n",
    "print('Options initialised')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74517e22-5636-4004-84c5-3cc416276054",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CUDA / GPU Setup\n",
    "This sets up the 'device' variable containing GPU information, and the custom dataset and dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c3c79a-3f60-4ca3-a6e9-b967929a3c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mGPU available!\u001b[0m\n",
      "Total number of available devices:  \u001b[0;33m1\u001b[0m\n",
      "total_n_samples_train: 510\n",
      "Sum of the weights for the month: 1.0\n",
      "Sum of the weights for the month: 510.00000000000006\n",
      "Sum of the weights for the icechart_provider: 510.0\n",
      "Sum of the weights for the Sentinel_mission_identifier: 510.0\n",
      "Sum of the weights for the location: 510.0\n",
      "Sum of the weights for the difficult_location: 509.99961427193847\n",
      "weight values after location: 1.0\n",
      "GPU and data setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Get GPU resources.\n",
    "if torch.cuda.is_available():\n",
    "    print(colour_str('GPU available!', 'green'))\n",
    "    print('Total number of available devices: ', colour_str(torch.cuda.device_count(), 'orange'))\n",
    "    device = torch.device(f\"cuda:{train_options['gpu_id']}\")\n",
    "\n",
    "else:\n",
    "    print(colour_str('GPU not available.', 'red'))\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Custom dataset and dataloader.\n",
    "dataset = AI4ArcticChallengeDataset(files=train_options['train_list'], options=train_options, get_metadata=train_options['get_metadata'])\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=None, shuffle=True, num_workers=train_options['num_workers'], pin_memory=True)\n",
    "# - Setup of the validation dataset/dataloader. The same is used for model testing in 'test_upload.ipynb'.\n",
    "dataset_val = AI4ArcticChallengeTestDataset(options=train_options, files=train_options['validate_list'], get_metadata=train_options['get_metadata'])\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=None, num_workers=train_options['num_workers_val'], shuffle=False)\n",
    "\n",
    "print('GPU and data setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e9849d-da01-402e-a79f-2f196618fb21",
   "metadata": {},
   "source": [
    "### Example of Model, optimiser and loss function setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df663da8-9779-4f8e-b641-29c9ea4e6036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss functions used are: {'SIC': MSELoss(), 'SOD': CrossEntropyLoss(), 'FLOE': CrossEntropyLoss()}\n",
      "Model setup complete\n"
     ]
    }
   ],
   "source": [
    "# Setup U-Net model, adam optimizer, loss function and dataloader.\n",
    "if train_options['transfer_learning']:\n",
    "    net = UNetTrans(options=train_options).to(device)\n",
    "    # print(net.state_dict().keys())\n",
    "else:\n",
    "    net = UNet(options=train_options).to(device)\n",
    "optimizer = torch.optim.Adam(list(net.parameters()), lr=train_options['lr'])\n",
    "torch.backends.cudnn.benchmark = True  # Selects the kernel with the best performance for the GPU and given input size.\n",
    "\n",
    "# Loss functions to use for each sea ice parameter.\n",
    "# The ignore_index argument discounts the masked values, ensuring that the model is not using these pixels to train on.\n",
    "# It is equivalent to multiplying the loss of the relevant masked pixel with 0.\n",
    "loss_functions = {chart: torch.nn.CrossEntropyLoss(ignore_index=train_options['class_fill_values'][chart]) \\\n",
    "                                                   for chart in train_options['charts']}\n",
    "# use regression loss for SIC\n",
    "if train_options['loss_sic'] == 'regression':\n",
    "    loss_functions['SIC'] = torch.nn.MSELoss()\n",
    "\n",
    "print(f\"The loss functions used are: {loss_functions}\")\n",
    "print('Model setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2980de-1025-4b75-9c43-0c3023a2d12c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example of model training and validation loop\n",
    "A simple model training loop following by a simple validation loop. Validation is carried out on full scenes, i.e. no cropping or stitching. If there is not enough space on the GPU, then try to do it on the cpu. This can be done by using 'net = net.cpu()'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7136c1c-22b2-4b59-b6eb-a9824748faff",
   "metadata": {},
   "source": [
    "### Workflow with MLflow\n",
    "\n",
    "- every model needs to be initiated with start_run() function\n",
    "- parameters can be logged with log_params() method\n",
    "- metrics are added with log_metric() with specified name and value\n",
    "- model can be stored into the model storage as artifact using corresponding flavour\n",
    "- for using MLflow autologing, model needs to use one of the supported flavours, eg. pytorch-lightning, fastai, tensorflow, xgboost or others - see [full list](https://www.mlflow.org/docs/latest/tracking.html#automatic-logging) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb870e4-4083-4ead-a4f8-919d1f79598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_options['development']:\n",
    "    ## setting up the sqlite database for tracking of experiments in MLflow\n",
    "    mlflow.set_tracking_uri('sqlite:///' + os.path.expanduser(os.environ[\"MLFLOW_BACKEND_STORE_PATH\"]))\n",
    "    os.path.expanduser(os.environ[\"MLFLOW_BACKEND_STORE_PATH\"])\n",
    "\n",
    "    ## setting the used experiment - if do not exist, new one will be created\n",
    "    e = mlflow.set_experiment(train_options['model_codename'])\n",
    "    e.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f1fdbd6-c674-4dc3-b271-2b3660a55646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing an ealy stopper\n",
    "class EarlyStopper:\n",
    "    \"\"\"\n",
    "    Stops the training early iff the validation loss does not increase anymore more than a small delta.\n",
    "    As the FLOE is weighted only half as much as the other two, the model does only need to get better half as much there.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=1, min_delta=0.1):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.max_val_score = -np.inf\n",
    "        \n",
    "    def early_stop(self, combined_score, best_combined_score):\n",
    "        # does not improve enough anymore: < old best + delta\n",
    "        if combined_score <= (self.max_val_score + self.min_delta):\n",
    "            self.counter += 1\n",
    "        else:\n",
    "            self.max_val_score = best_combined_score # such that there is not a crawling improvement not seen\n",
    "            self.counter = 0\n",
    "        return self.counter > self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d00e418-ff77-4948-92bd-0b2313b281d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc370f0588c449aab9fa778b2415a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ccf8522eed45a185791e11d0b0116f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in computing combined score for sample 0 in batch 0 in epoch 0, Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "SIC: shape of pred: (0,), shape of true: (0,)\n",
      "SOD: shape of pred: (0,), shape of true: (0,)\n",
      "FLOE: shape of pred: (0,), shape of true: (0,)\n",
      "Error in computing combined score for sample 0 in batch 1 in epoch 0, Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "SIC: shape of pred: (0,), shape of true: (0,)\n",
      "SOD: shape of pred: (0,), shape of true: (0,)\n",
      "FLOE: shape of pred: (0,), shape of true: (0,)\n",
      "Mean training loss: 49.867\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61b9ce7c1cb4cc6a08d2a2340ca4f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final batch loss: 49.661\n",
      "Epoch 0 score:\n",
      "SIC r2_metric: -114.737%\n",
      "SOD f1_metric: 0.995%\n",
      "FLOE f1_metric: 0.0%\n",
      "Combined score: -45.497%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a56d6eb1cb437d980091d16a3b11a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in computing combined score for sample 0 in batch 0 in epoch 1, Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "SIC: shape of pred: (0,), shape of true: (0,)\n",
      "SOD: shape of pred: (0,), shape of true: (0,)\n",
      "FLOE: shape of pred: (0,), shape of true: (0,)\n",
      "Error in computing combined score for sample 0 in batch 1 in epoch 1, Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "SIC: shape of pred: (0,), shape of true: (0,)\n",
      "SOD: shape of pred: (0,), shape of true: (0,)\n",
      "FLOE: shape of pred: (0,), shape of true: (0,)\n",
      "Mean training loss: 49.104\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2b0bb8052f499f80e013130b513061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final batch loss: 48.931\n",
      "Epoch 1 score:\n",
      "SIC r2_metric: -114.875%\n",
      "SOD f1_metric: 0.941%\n",
      "FLOE f1_metric: 0.0%\n",
      "Combined score: -45.574%\n"
     ]
    }
   ],
   "source": [
    "best_combined_score = 0  # Best weighted model score.\n",
    "# early_stopper = EarlyStopper(patience = 4, min_delta=0.3)\n",
    "if train_options['get_metadata']:\n",
    "    metadata = pd.DataFrame(columns=['sentinel_mission_identifier',\n",
    "                                    'image_acquisition_start_date',\n",
    "                                    'image_acquisition_start_date_year', 'image_acquisition_start_date_month', 'image_acquisition_start_date_hour',\n",
    "                                    'row_rand', 'col_rand', 'sample_n',\n",
    "                                    'icechart_provider', 'location',\n",
    "                                    'epoch_no', 'type', 'score_combined',\n",
    "                                    'loss_SIC', 'loss_SOD', 'loss_FLOE', 'loss_combined',\n",
    "                                    'score_SIC', 'ice_characteristcs_SIC',\n",
    "                                    'score_SOD', 'ice_characteristcs_SOD',\n",
    "                                    'score_FLOE', 'ice_characteristcs_FLOE',])\n",
    "    metadata_path = os.path.join(train_options['path_to_env'], f\"metadata_runs/{train_options['model_codename']}_metadata.csv\")\n",
    "    metadata.to_csv(metadata_path, index=False)\n",
    "\n",
    "with mlflow.start_run() if not train_options['development'] else nullcontext() as run:\n",
    "    mlflow.log_params(train_options['chart_metric'])\n",
    "\n",
    "    # -- Training Loop -- #\n",
    "    for epoch in tqdm(iterable=range(train_options['epochs']), position=0):\n",
    "        gc.collect()  # Collect garbage to free memory.\n",
    "        loss_sum = torch.tensor([0.])  # To sum the batch losses during the epoch.\n",
    "        net.train()  # Set network to evaluation mode.\n",
    "\n",
    "        # Loops though batches in queue.\n",
    "        for i, (batch_x, batch_y, masks, metadata_batch) in enumerate(tqdm(iterable=dataloader, total=train_options['epoch_len'], colour='red', position=0)):\n",
    "            torch.cuda.empty_cache()  # Empties the GPU cache freeing up memory.\n",
    "            loss_batch = 0  # Reset from previous batch.\n",
    "\n",
    "            # - Update metadata\n",
    "            if train_options['get_metadata']:\n",
    "                metadata_batch['epoch_no'] = epoch\n",
    "                metadata_batch['type'] = 'train'\n",
    "                metadata_batch['score_combined'] = np.nan\n",
    "\n",
    "            # - Transfer to device.\n",
    "            batch_x = batch_x.to(device, non_blocking=True)\n",
    "\n",
    "            # - Mixed precision training. (Saving memory)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # - Forward pass. \n",
    "                output = net(batch_x)\n",
    "\n",
    "                # - Calculate loss.\n",
    "                for chart in train_options['charts']:\n",
    "                    # - weight FLOE to balance it with the metrics\n",
    "                    # TODO: weight SIC loss as it is a different kind of loss?\n",
    "                    weight = 1 if chart != 'FLOE' else 0.5\n",
    "\n",
    "                    # - masking for sic loss has to be done here\n",
    "                    if chart == 'SIC' and train_options['loss_sic'] == 'regression':\n",
    "                        # - mask out the masked values\n",
    "                        mask = masks[chart].to(device, non_blocking=True)\n",
    "                        mask_out = mask[:,None,:,:]  # add channel dimension\n",
    "                        # output[chart] = output[chart][~mask_out]  # .to(device)\n",
    "                        # batch_y[chart] = batch_y[chart][~mask].float().to(device)\n",
    "                        # somehow loss_temp as to be calculated this way (no redefinition of output[chart])\n",
    "                        loss_temp = weight * loss_functions[chart](input=output[chart][~mask_out].to(device), \n",
    "                                                                   target=batch_y[chart][~mask].float().to(device))\n",
    "                    else:\n",
    "                        loss_temp = weight * loss_functions[chart](input=output[chart], target=batch_y[chart].to(device))\n",
    "\n",
    "                    if train_options['get_metadata']:\n",
    "                        metadata_batch[f'loss_{chart}'] = loss_temp.detach().item()\n",
    "                    loss_batch += loss_temp\n",
    "\n",
    "                    try:\n",
    "                        mlflow.log_metric(key=\"chart_loss\", value=loss_batch)\n",
    "                    except Exception as e:\n",
    "                        print(f\"In epoch {epoch}, batch {i} the following error occured \\n {e}\")\n",
    "                        continue\n",
    "\n",
    "                if train_options['get_metadata']:\n",
    "                    metadata_batch[f'loss_combined'] = loss_batch.detach().item()\n",
    "\n",
    "                # - recreate each patch from batch and calculate the metrics for it\n",
    "                # uses an adapted code from the validation loop below\n",
    "                # uses an adapted code from the validation loop below\n",
    "                for j in range(train_options['batch_size']):\n",
    "                    mask_single_patch = masks[chart][j]\n",
    "\n",
    "                    output_single_patch_temp = {}\n",
    "                    for chart in train_options['charts']:\n",
    "                        if chart == 'SIC' and train_options['loss_sic'] == 'regression':\n",
    "                            output_single_patch_temp[chart] = output[chart][j].squeeze().cpu().detach().numpy()\n",
    "                        else:\n",
    "                            output_single_patch_temp[chart] = torch.argmax(output[chart][j], dim=0).squeeze().cpu().numpy()\n",
    "\n",
    "                    output_single_patch = {chart: output_single_patch_temp[chart][~mask_single_patch] for chart in train_options['charts']}\n",
    "\n",
    "                    batch_y_single_patch = {chart: batch_y[chart][j][~mask_single_patch].cpu().numpy() for chart in train_options['charts']}\n",
    "\n",
    "                    # -- update metadata for each element in the batch = 'sample_n'\n",
    "                    try:\n",
    "                        combined_score, scores = compute_metrics(pred=output_single_patch, true=batch_y_single_patch, charts=train_options['charts'],\n",
    "                                                            metrics=train_options['chart_metric'])\n",
    "                    except ValueError as e:\n",
    "                        scores = {chart: np.nan for chart in train_options['charts']}\n",
    "                        combined_score = np.nan\n",
    "                        print(f\"Error in computing combined score for sample {j} in batch {i} in epoch {epoch}, {e}\")\n",
    "                        for chart in train_options['charts']:\n",
    "                            print(f\"{chart}: shape of pred: {output_single_patch[chart].shape}, shape of true: {batch_y_single_patch[chart].shape}\")\n",
    "                        continue\n",
    "\n",
    "                    for chart in train_options['charts']:\n",
    "                        # because the index should be the same as the sample_n\n",
    "                        metadata_batch.loc[(j, 'score_' + chart)] = scores[chart]\n",
    "                        metadata_batch.loc[(j, 'ice_characteristcs_' + chart)] = float(torch.median(batch_y[chart]))\n",
    "                    metadata_batch.loc[(j, 'score_combined')] = combined_score\n",
    "\n",
    "                    del mask_single_patch, batch_y_single_patch, output_single_patch, output_single_patch_temp, combined_score, scores\n",
    "\n",
    "\n",
    "            # - Reset gradients from previous pass.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # - Backward pass.\n",
    "            loss_batch.backward()\n",
    "\n",
    "            # - Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # - Add batch loss.\n",
    "            loss_sum += loss_batch.detach().item()\n",
    "\n",
    "            # - Average loss for displaying\n",
    "            loss_epoch = torch.true_divide(loss_sum, i + 1).detach().item()\n",
    "            print('\\rMean training loss: ' + f'{loss_epoch:.3f}', end='\\r')\n",
    "\n",
    "            # - update metdata\n",
    "            metadata = pd.concat([metadata, metadata_batch], ignore_index=True)\n",
    "\n",
    "            # - save and log the metadata\n",
    "            metadata_batch.to_csv(metadata_path, mode='a', header=False, index=False)  # append to the csv file\n",
    "            try:\n",
    "                mlflow.log_artifact(f\"metadata_runs/{train_options['model_codename']}_metadata.csv\")\n",
    "            except Exception as e:\n",
    "                print(f\"While logging the train metadata the following error occured \\n {e}\")\n",
    "\n",
    "            # - Log metrics to MLflow\n",
    "            try:\n",
    "                mlflow.log_metric(key=\"mean_loss\", value=loss_epoch)\n",
    "            except Exception as e:\n",
    "                print(f\"In epoch {epoch}, batch {i} the following error occured \\n {e}\")\n",
    "                continue\n",
    "            del output, batch_x, batch_y, masks, metadata_batch # Free memory.\n",
    "        del loss_sum\n",
    "\n",
    "        # -- Validation Loop -- #\n",
    "        loss_batch = loss_batch.detach().item()  # For printing after the validation loop.\n",
    "\n",
    "        # - Stores the output and the reference pixels to calculate the scores after inference on all the scenes.\n",
    "        outputs_flat = {chart: np.array([]) for chart in train_options['charts']}\n",
    "        inf_ys_flat = {chart: np.array([]) for chart in train_options['charts']}\n",
    "\n",
    "        net.eval()  # Set network to evaluation mode.\n",
    "        # - Loops though scenes in queue.\n",
    "        for inf_x, inf_y, masks, name, metadata_scene in tqdm(iterable=dataloader_val, total=len(train_options['validate_list']), colour='green', position=0):\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            # - update metadata\n",
    "            if train_options['get_metadata']:\n",
    "                metadata_scene['epoch_no'] = epoch\n",
    "                metadata_scene['type'] = 'test'\n",
    "                outputs_scene, inf_ys_scene = {}, {}\n",
    "\n",
    "            # - crop the test scene to save memory in development mode\n",
    "            if train_options['development']:\n",
    "                # if we only take the border we get only masked values\n",
    "                crop_start = 1000\n",
    "                crop_size = 200\n",
    "                crop_idx = slice(crop_start, crop_start + crop_size)\n",
    "                inf_x = inf_x[:, :, crop_idx, crop_idx]\n",
    "                inf_y = {chart: inf_y[chart][crop_idx, crop_idx] for chart in train_options['charts']}\n",
    "                masks = {chart: masks[chart][crop_idx, crop_idx] for chart in train_options['charts']}\n",
    "\n",
    "            # - Ensures that no gradients are calculated, which otherwise take up a lot of space on the GPU.\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                inf_x = inf_x.to(device, non_blocking=True)\n",
    "                output = net(inf_x)\n",
    "\n",
    "            # - Final output layer, and storing of non masked pixels.\n",
    "            for chart in train_options['charts']:\n",
    "                if chart == 'SIC' and train_options['loss_sic'] == 'regression':\n",
    "                    output[chart] = output[chart].squeeze().cpu().numpy()\n",
    "                else:\n",
    "                    output[chart] = torch.argmax(output[chart], dim=1).squeeze().cpu().numpy()\n",
    "                outputs_flat[chart] = np.append(outputs_flat[chart], output[chart][~masks[chart]])\n",
    "                inf_ys_flat[chart] = np.append(inf_ys_flat[chart], inf_y[chart][~masks[chart]].numpy())\n",
    "\n",
    "                # - calculate the median values for each scene\n",
    "                if train_options['get_metadata']:\n",
    "                    outputs_scene[chart] = output[chart][~masks[chart]]\n",
    "                    inf_ys_scene[chart] = inf_y[chart][~masks[chart]].numpy()\n",
    "\n",
    "                    # in development mode it is possible that every value of the scene is masked\n",
    "                    # this is only possible for the test scenes, because the training dataloader makes sure that there are not too many masked values\n",
    "                    if np.all(~masks[chart].numpy() == False):\n",
    "                        print(f\"There are no unmasked values in {chart} of {name}.\")\n",
    "                        outputs_scene[chart], inf_ys_scene[chart] = np.nan, np.nan\n",
    "\n",
    "            # - update metadata\n",
    "            if train_options['get_metadata']:\n",
    "                for chart in train_options['charts']:\n",
    "                    metadata_scene[f'score_{chart}'] = np.median(outputs_scene[chart])\n",
    "                    metadata_scene[f'ice_characteristcs_{chart}'] = np.median(inf_ys_scene[chart])\n",
    "\n",
    "                combined_score_scene, scores_scene = compute_metrics(true=inf_ys_scene, pred=outputs_scene, charts=train_options['charts'],\n",
    "                                                                     metrics=train_options['chart_metric'])\n",
    "                metadata_scene['score_combined'] = combined_score_scene\n",
    "                metadata = pd.concat([metadata, metadata_scene], ignore_index=True)\n",
    "\n",
    "                # - save and log the metadata\n",
    "                metadata_scene.to_csv(metadata_path, mode='a', header=False, index=False)  # append to the csv file\n",
    "                try:\n",
    "                    mlflow.log_artifact(f\"metadata_runs/{train_options['model_codename']}_metadata.csv\")\n",
    "                except Exception as e:\n",
    "                    print(f\"While logging the test metadata the following error occured \\n {e}\")\n",
    "\n",
    "            del inf_x, inf_y, masks, name, metadata_scene, output, combined_score_scene, scores_scene  # Free memory.\n",
    "\n",
    "        # - Compute the relevant scores.\n",
    "        combined_score, scores = compute_metrics(true=inf_ys_flat, pred=outputs_flat, charts=train_options['charts'],\n",
    "                                                 metrics=train_options['chart_metric'])\n",
    "\n",
    "        print(\"\")\n",
    "        print(f\"Final batch loss: {loss_batch:.3f}\")\n",
    "        print(f\"Epoch {epoch} score:\")\n",
    "        for chart in train_options['charts']:\n",
    "            print(f\"{chart} {train_options['chart_metric'][chart]['func'].__name__}: {scores[chart]}%\")\n",
    "        print(f\"Combined score: {combined_score}%\")\n",
    "        \n",
    "        try:\n",
    "            mlflow.log_metric(key=\"final_batch_loss\", value=loss_batch)\n",
    "            mlflow.log_metric(key=\"combined_score\", value=combined_score)\n",
    "        except Exception as e:\n",
    "            print(f\"In epoch {epoch}, batch {i} the following error occured \\n {e}\")\n",
    "            continue\n",
    "\n",
    "        # If the scores is better than the previous epoch, then save the model and rename the image to best_validation.\n",
    "        if combined_score > best_combined_score:\n",
    "            best_combined_score = combined_score\n",
    "            torch.save(obj={'model_state_dict': net.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'epoch': epoch},\n",
    "                            f=f\"models/{train_options['model_codename']}_{epoch}_best_model\")\n",
    "        elif epoch % 25 == 0:\n",
    "            torch.save(obj={'model_state_dict': net.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'epoch': epoch},\n",
    "                            f=f\"models/{train_options['model_codename']}_{epoch}_intermediate_model\")\n",
    "        elif epoch == (train_options['epochs']-1):\n",
    "            torch.save(obj={'model_state_dict': net.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'epoch': epoch},\n",
    "                            f=f\"models/{train_options['model_codename']}_{epoch}_atlast_model\")\n",
    "        # elif early_stopper(combined_score, best_combined_score):\n",
    "        #     break\n",
    "            \n",
    "        del inf_ys_flat, outputs_flat  # Free memory.\n",
    "\n",
    "# - Log the metadata as an artifact\n",
    "if train_options['get_metadata']:\n",
    "    try:\n",
    "        mlflow.log_artifact(f\"metadata_runs/{train_options['model_codename']}_metadata.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"While finally logging the metadata the following error occured \\n {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentinel_mission_identifier</th>\n",
       "      <th>image_acquisition_start_date</th>\n",
       "      <th>image_acquisition_start_date_year</th>\n",
       "      <th>image_acquisition_start_date_month</th>\n",
       "      <th>image_acquisition_start_date_hour</th>\n",
       "      <th>row_rand</th>\n",
       "      <th>col_rand</th>\n",
       "      <th>sample_n</th>\n",
       "      <th>icechart_provider</th>\n",
       "      <th>location</th>\n",
       "      <th>score_SIC</th>\n",
       "      <th>score_SOD</th>\n",
       "      <th>score_FLOE</th>\n",
       "      <th>score_combined</th>\n",
       "      <th>loss_SIC</th>\n",
       "      <th>loss_SOD</th>\n",
       "      <th>loss_FLOE</th>\n",
       "      <th>loss_combined</th>\n",
       "      <th>ice_characteristcs_SIC</th>\n",
       "      <th>ice_characteristcs_SOD</th>\n",
       "      <th>ice_characteristcs_FLOE</th>\n",
       "      <th>epoch_no</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A</td>\n",
       "      <td>2019-11-15 08:29:16</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>907</td>\n",
       "      <td>3509</td>\n",
       "      <td>1</td>\n",
       "      <td>dmi</td>\n",
       "      <td>CentralEast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.812527</td>\n",
       "      <td>1.665758</td>\n",
       "      <td>1.050130</td>\n",
       "      <td>58.528412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1B</td>\n",
       "      <td>2021-05-21 08:21:26</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3457</td>\n",
       "      <td>3679</td>\n",
       "      <td>2</td>\n",
       "      <td>dmi</td>\n",
       "      <td>SouthEast</td>\n",
       "      <td>-71893.023000</td>\n",
       "      <td>22.612</td>\n",
       "      <td>25.469</td>\n",
       "      <td>-28743.071</td>\n",
       "      <td>55.812527</td>\n",
       "      <td>1.665758</td>\n",
       "      <td>1.050130</td>\n",
       "      <td>58.528412</td>\n",
       "      <td>8.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1A</td>\n",
       "      <td>2019-11-15 08:29:16</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>907</td>\n",
       "      <td>3509</td>\n",
       "      <td>1</td>\n",
       "      <td>dmi</td>\n",
       "      <td>CentralEast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.249973</td>\n",
       "      <td>1.629552</td>\n",
       "      <td>1.042213</td>\n",
       "      <td>57.921738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1B</td>\n",
       "      <td>2021-05-21 08:21:26</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3457</td>\n",
       "      <td>3679</td>\n",
       "      <td>2</td>\n",
       "      <td>dmi</td>\n",
       "      <td>SouthEast</td>\n",
       "      <td>-71656.981000</td>\n",
       "      <td>32.642</td>\n",
       "      <td>26.172</td>\n",
       "      <td>-28644.501</td>\n",
       "      <td>55.249973</td>\n",
       "      <td>1.629552</td>\n",
       "      <td>1.042213</td>\n",
       "      <td>57.921738</td>\n",
       "      <td>8.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1B</td>\n",
       "      <td>2021-02-02 21:18:45</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dmi</td>\n",
       "      <td>SouthWest</td>\n",
       "      <td>-0.191406</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>37.113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S1B</td>\n",
       "      <td>2020-10-07 21:03:52</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dmi</td>\n",
       "      <td>NorthWest</td>\n",
       "      <td>-0.204102</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1A</td>\n",
       "      <td>2019-11-15 08:29:16</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>907</td>\n",
       "      <td>3509</td>\n",
       "      <td>1</td>\n",
       "      <td>dmi</td>\n",
       "      <td>CentralEast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.745750</td>\n",
       "      <td>1.599931</td>\n",
       "      <td>1.041325</td>\n",
       "      <td>57.387005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1B</td>\n",
       "      <td>2021-05-21 08:21:26</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3457</td>\n",
       "      <td>3679</td>\n",
       "      <td>2</td>\n",
       "      <td>dmi</td>\n",
       "      <td>SouthEast</td>\n",
       "      <td>-72071.174000</td>\n",
       "      <td>48.822</td>\n",
       "      <td>23.863</td>\n",
       "      <td>-28804.168</td>\n",
       "      <td>54.745750</td>\n",
       "      <td>1.599931</td>\n",
       "      <td>1.041325</td>\n",
       "      <td>57.387005</td>\n",
       "      <td>8.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1A</td>\n",
       "      <td>2019-11-15 08:29:16</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>907</td>\n",
       "      <td>3509</td>\n",
       "      <td>1</td>\n",
       "      <td>dmi</td>\n",
       "      <td>CentralEast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.290627</td>\n",
       "      <td>1.582168</td>\n",
       "      <td>1.045431</td>\n",
       "      <td>56.918228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1B</td>\n",
       "      <td>2021-05-21 08:21:26</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3457</td>\n",
       "      <td>3679</td>\n",
       "      <td>2</td>\n",
       "      <td>dmi</td>\n",
       "      <td>SouthEast</td>\n",
       "      <td>-72741.749000</td>\n",
       "      <td>62.197</td>\n",
       "      <td>21.411</td>\n",
       "      <td>-29067.539</td>\n",
       "      <td>54.290627</td>\n",
       "      <td>1.582168</td>\n",
       "      <td>1.045431</td>\n",
       "      <td>56.918228</td>\n",
       "      <td>8.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1B</td>\n",
       "      <td>2021-02-02 21:18:45</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dmi</td>\n",
       "      <td>SouthWest</td>\n",
       "      <td>-0.200439</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1B</td>\n",
       "      <td>2020-10-07 21:03:52</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dmi</td>\n",
       "      <td>NorthWest</td>\n",
       "      <td>-0.211060</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentinel_mission_identifier image_acquisition_start_date  \\\n",
       "0                          S1A          2019-11-15 08:29:16   \n",
       "1                          S1B          2021-05-21 08:21:26   \n",
       "2                          S1A          2019-11-15 08:29:16   \n",
       "3                          S1B          2021-05-21 08:21:26   \n",
       "4                          S1B          2021-02-02 21:18:45   \n",
       "5                          S1B          2020-10-07 21:03:52   \n",
       "6                          S1A          2019-11-15 08:29:16   \n",
       "7                          S1B          2021-05-21 08:21:26   \n",
       "8                          S1A          2019-11-15 08:29:16   \n",
       "9                          S1B          2021-05-21 08:21:26   \n",
       "10                         S1B          2021-02-02 21:18:45   \n",
       "11                         S1B          2020-10-07 21:03:52   \n",
       "\n",
       "   image_acquisition_start_date_year image_acquisition_start_date_month  \\\n",
       "0                               2019                                 11   \n",
       "1                               2021                                  5   \n",
       "2                               2019                                 11   \n",
       "3                               2021                                  5   \n",
       "4                               2021                                  2   \n",
       "5                               2020                                 10   \n",
       "6                               2019                                 11   \n",
       "7                               2021                                  5   \n",
       "8                               2019                                 11   \n",
       "9                               2021                                  5   \n",
       "10                              2021                                  2   \n",
       "11                              2020                                 10   \n",
       "\n",
       "   image_acquisition_start_date_hour row_rand col_rand sample_n  \\\n",
       "0                                  8      907     3509        1   \n",
       "1                                  8     3457     3679        2   \n",
       "2                                  8      907     3509        1   \n",
       "3                                  8     3457     3679        2   \n",
       "4                                 21      NaN      NaN      NaN   \n",
       "5                                 21      NaN      NaN      NaN   \n",
       "6                                  8      907     3509        1   \n",
       "7                                  8     3457     3679        2   \n",
       "8                                  8      907     3509        1   \n",
       "9                                  8     3457     3679        2   \n",
       "10                                21      NaN      NaN      NaN   \n",
       "11                                21      NaN      NaN      NaN   \n",
       "\n",
       "   icechart_provider     location     score_SIC  score_SOD  score_FLOE  \\\n",
       "0                dmi  CentralEast           NaN        NaN         NaN   \n",
       "1                dmi    SouthEast -71893.023000     22.612      25.469   \n",
       "2                dmi  CentralEast           NaN        NaN         NaN   \n",
       "3                dmi    SouthEast -71656.981000     32.642      26.172   \n",
       "4                dmi    SouthWest     -0.191406      4.000       4.000   \n",
       "5                dmi    NorthWest     -0.204102      2.000       4.000   \n",
       "6                dmi  CentralEast           NaN        NaN         NaN   \n",
       "7                dmi    SouthEast -72071.174000     48.822      23.863   \n",
       "8                dmi  CentralEast           NaN        NaN         NaN   \n",
       "9                dmi    SouthEast -72741.749000     62.197      21.411   \n",
       "10               dmi    SouthWest     -0.200439      6.000       4.000   \n",
       "11               dmi    NorthWest     -0.211060      6.000       4.000   \n",
       "\n",
       "    score_combined   loss_SIC  loss_SOD  loss_FLOE  loss_combined  \\\n",
       "0              NaN  55.812527  1.665758   1.050130      58.528412   \n",
       "1       -28743.071  55.812527  1.665758   1.050130      58.528412   \n",
       "2              NaN  55.249973  1.629552   1.042213      57.921738   \n",
       "3       -28644.501  55.249973  1.629552   1.042213      57.921738   \n",
       "4           37.113        NaN       NaN        NaN            NaN   \n",
       "5            0.000        NaN       NaN        NaN            NaN   \n",
       "6              NaN  54.745750  1.599931   1.041325      57.387005   \n",
       "7       -28804.168  54.745750  1.599931   1.041325      57.387005   \n",
       "8              NaN  54.290627  1.582168   1.045431      56.918228   \n",
       "9       -29067.539  54.290627  1.582168   1.045431      56.918228   \n",
       "10           0.000        NaN       NaN        NaN            NaN   \n",
       "11           0.000        NaN       NaN        NaN            NaN   \n",
       "\n",
       "    ice_characteristcs_SIC  ice_characteristcs_SOD  ice_characteristcs_FLOE  \\\n",
       "0                      NaN                     NaN                      NaN   \n",
       "1                      8.0                   255.0                    255.0   \n",
       "2                      NaN                     NaN                      NaN   \n",
       "3                      8.0                   255.0                    255.0   \n",
       "4                     10.0                     4.0                      5.0   \n",
       "5                      0.0                     0.0                      0.0   \n",
       "6                      NaN                     NaN                      NaN   \n",
       "7                      8.0                   255.0                    255.0   \n",
       "8                      NaN                     NaN                      NaN   \n",
       "9                      8.0                   255.0                    255.0   \n",
       "10                    10.0                     4.0                      5.0   \n",
       "11                     0.0                     0.0                      0.0   \n",
       "\n",
       "   epoch_no   type  \n",
       "0         0  train  \n",
       "1         0  train  \n",
       "2         0  train  \n",
       "3         0  train  \n",
       "4         0   test  \n",
       "5         0   test  \n",
       "6         1  train  \n",
       "7         1  train  \n",
       "8         1  train  \n",
       "9         1  train  \n",
       "10        1   test  \n",
       "11        1   test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(metadata)\n",
    "    # display(metadata[metadata['type'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2955b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
