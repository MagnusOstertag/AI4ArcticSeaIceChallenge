{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9662657d-0ee6-408d-94fe-da71539dcfd5",
   "metadata": {},
   "source": [
    "# AutoICE - test model and prepare upload package\n",
    "This notebook tests the 'best_model', created in the quickstart notebook, with the tests scenes exempt of reference data. The model outputs are stored per scene and chart in an xarray Dataset in individual Dataarrays. The xarray Dataset is saved and compressed in an .nc file ready to be uploaded to the AI4EO.eu platform. Finally, the scene chart inference is shown.\n",
    "\n",
    "The first cell imports necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cabf3fe-44c3-42f0-b061-5a70b64379be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Built-in modules -- #\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "# -- Third-part modules -- #\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import xarray as xr\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "import tracemalloc\n",
    "\n",
    "# --Proprietary modules -- #\n",
    "from functions import chart_cbar, r2_metric, f1_metric, compute_metrics\n",
    "from loaders import AI4ArcticChallengeTestDataset\n",
    "from unet import UNet\n",
    "from utils import CHARTS, SIC_LOOKUP, SOD_LOOKUP, FLOE_LOOKUP, SCENE_VARIABLES, colour_str\n",
    "from unet import FeatureMap\n",
    "%store -r train_options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b270975-ef64-45c0-bfa0-5f3d48504ab5",
   "metadata": {},
   "source": [
    "### Setup of the GPU resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3e19a1-76d0-4047-b4a4-8b5f8af19bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mGPU not available.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get GPU resources.\n",
    "if torch.cuda.is_available():\n",
    "    print(colour_str('GPU available!', 'green'))\n",
    "    print('Total number of available devices: ', colour_str(torch.cuda.device_count(), 'orange'))\n",
    "    device = torch.device(f\"cuda:{train_options['gpu_id']}\")\n",
    "\n",
    "else:\n",
    "    print(colour_str('GPU not available.', 'red'))\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d365e-0a78-43f2-9182-776148c80d31",
   "metadata": {},
   "source": [
    "### Load the model and stored parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e164255-8528-46b3-9ce6-6bc27c0effae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model.\n",
      "Model successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "print('Loading model.')\n",
    "# Setup U-Net model, adam optimizer, loss function and dataloader.\n",
    "net = UNet(options=train_options).to(device)\n",
    "\n",
    "model_path = 'models/PizzaQuattroFormaggi_34_best_model'\n",
    "if train_options['loss_sic'] == 'classification':\n",
    "    net.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "elif train_options['loss_sic'] == 'regression':\n",
    "    net.sic_feature_map = unet.FeatureMap(input_n=train_options['unet_conv_filters'][0],\n",
    "                                                  output_n=1,)\n",
    "    net.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "\n",
    "print('Model successfully loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16af23-a901-4ca6-8d75-7a54d66a1eaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare the scene list, dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f92af3-32ab-4752-832a-29b5972ac375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup ready\n"
     ]
    }
   ],
   "source": [
    "with open(train_options['path_to_env'] + 'datalists/testset.json') as file:\n",
    "    train_options['test_list'] = json.loads(file.read())\n",
    "train_options['test_list'] = [file[17:32] + '_' + file[77:80] + '_prep.nc' for file in train_options['test_list']]\n",
    "train_options['path_to_processed_data'] += 'test_data'  # The test data is stored in a separate folder inside the training data.\n",
    "upload_package = xr.Dataset()  # To store model outputs.\n",
    "dataset = AI4ArcticChallengeTestDataset(options=train_options, files=train_options['test_list'], test=True)\n",
    "asid_loader = torch.utils.data.DataLoader(dataset, batch_size=None, num_workers=train_options['num_workers_val'], shuffle=False)\n",
    "print('Setup ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba9a9d8-2c8a-4c39-98c4-1b153d73dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_bytes(size):\n",
    "    # 2**10 = 1024\n",
    "    power = 2**10\n",
    "    n = 0\n",
    "    power_labels = {0 : '', 1: 'kilo', 2: 'mega', 3: 'giga', 4: 'tera'}\n",
    "    while size > power:\n",
    "        size /= power\n",
    "        n += 1\n",
    "    return size, power_labels[n]+'bytes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20730e27-e0cc-4c1a-87a8-f2145d32f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d920296e0c47128b4966e58c0c5cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene name: 20180124T194759_dmi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conda/autoice/d163ac953e591afe74a6e27636e7584eb349f707f4365d74b1eda380edb75a78-20221130-125246-700756-50-torch_v1/lib/python3.9/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene name: 20210430T205436_dmi\n",
      "scene name: 20210506T075557_dmi\n",
      "scene name: 20201013T080448_dmi\n",
      "scene name: 20210328T202742_dmi\n",
      "scene name: 20210410T201933_dmi\n",
      "scene name: 20190810T110422_dmi\n",
      "scene name: 20211212T211242_dmi\n",
      "scene name: 20180623T114935_cis\n",
      "scene name: 20180707T113313_cis\n",
      "scene name: 20200719T123046_cis\n",
      "scene name: 20190406T102029_cis\n",
      "scene name: 20180903T123331_cis\n",
      "scene name: 20180716T110418_cis\n",
      "scene name: 20191011T131651_cis\n",
      "scene name: 20200217T102731_cis\n",
      "scene name: 20210512T214149_cis\n",
      "scene name: 20200701T114012_cis\n",
      "scene name: 20200319T101935_cis\n",
      "scene name: 20180917T121813_cis\n",
      "Saving upload_package. Compressing data with zlib.\n",
      "Testing completed.\n"
     ]
    }
   ],
   "source": [
    "print('Testing.')\n",
    "os.makedirs('inference', exist_ok=True)\n",
    "net.eval()\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "tracemalloc_snapshots = []\n",
    "tracemalloc.start()\n",
    "plotting = False\n",
    "\n",
    "for inf_x, _, masks, scene_name in tqdm(iterable=asid_loader, total=len(train_options['test_list']), colour='green', position=0):\n",
    "    scene_name = scene_name[:19]  # Removes the _prep.nc from the name.\n",
    "    print(f\"scene name: {scene_name}\")\n",
    "#    if device.type  == 'cpu':\n",
    "#        n_bytes, form = format_bytes(process.memory_info().rss)\n",
    "#        n_bytes_pack, form_pack = format_bytes(upload_package.nbytes)\n",
    "#        print(f\"Beginning {n_bytes:.2f} {form} with {n_bytes_pack:.2f} {form_pack} being the upload package\")\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        inf_x = inf_x.to(device, non_blocking=True)\n",
    "\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        output = net(inf_x)\n",
    "    \n",
    "#    if device.type  == 'cpu':\n",
    "#        n_bytes, form = format_bytes(process.memory_info().rss)\n",
    "#        print(f\"After Prediction {n_bytes:.2f} {form}\") \n",
    "\n",
    "    for chart in train_options['charts']:\n",
    "        if chart == 'SIC' and train_options['loss_sic'] == 'regression':\n",
    "            output[chart] = output[chart].squeeze().cpu().numpy()\n",
    "        else:\n",
    "            output[chart] = torch.argmax(output[chart], dim=1).squeeze().cpu().numpy()\n",
    "        upload_package[f\"{scene_name}_{chart}\"] = xr.DataArray(name=f\"{scene_name}_{chart}\", data=output[chart].astype('uint8'),\n",
    "                                                               dims=(f\"{scene_name}_{chart}_dim0\", f\"{scene_name}_{chart}_dim1\"))\n",
    "        del chart\n",
    "\n",
    "    if plotting == True:\n",
    "        # - Show the scene inference.\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "        for idx, chart in enumerate(train_options['charts']):\n",
    "            ax = axs[idx]\n",
    "            output[chart] = output[chart].astype(float)\n",
    "            output[chart][masks] = np.nan\n",
    "            ax.imshow(output[chart], vmin=0, vmax=train_options['n_classes'][chart] - 2, cmap='jet', interpolation='nearest')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            chart_cbar(ax=ax, n_classes=train_options['n_classes'][chart], chart=chart, cmap='jet')\n",
    "            del chart, idx\n",
    "\n",
    "        plt.suptitle(f\"Scene: {scene_name}\", y=0.65)\n",
    "        plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.5, hspace=-0)\n",
    "        fig.savefig(f\"inference/{scene_name}.png\", format='png', dpi=128, bbox_inches=\"tight\")\n",
    "        plt.close('all')\n",
    "\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "    \n",
    "    del inf_x, masks, output #, fig, ax, axs  # Free memory.\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "#    if device.type  == 'cpu':\n",
    "#        n_bytes, form = format_bytes(process.memory_info().rss)\n",
    "#        n_bytes_pack, form_pack = format_bytes(upload_package.nbytes)\n",
    "#        print(f\"End {n_bytes:.2f} {form} with {n_bytes_pack:.2f} {form_pack} being the upload package\\n\")\n",
    "        \n",
    "#    # memory leak analysis\n",
    "#    snapshot = tracemalloc.take_snapshot()\n",
    "#    tracemalloc_snapshots.append(snapshot)\n",
    "#    if len(tracemalloc_snapshots) > 2:\n",
    "#        top_stats = tracemalloc_snapshots[-1].compare_to(tracemalloc_snapshots[-2],'traceback')\n",
    "#        print(\"[ Top 5 differences ]\")\n",
    "#        for stat in top_stats[:10]:\n",
    "#            print(stat)\n",
    "#        print(\"\\n\\n\")\n",
    "        \n",
    "#    if device == 'cuda':\n",
    "#        torch.cuda.memory_summary(device=device, abbreviated=False)\n",
    "\n",
    "\n",
    "# - Save upload_package with zlib compression.\n",
    "print('Saving upload_package. Compressing data with zlib.')\n",
    "compression = dict(zlib=True, complevel=1)\n",
    "encoding = {var: compression for var in upload_package.data_vars}\n",
    "upload_package.to_netcdf('upload_package.nc', mode='w', format='netcdf4', engine='netcdf4', encoding=encoding)\n",
    "print('Testing completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a63d3d-aaa3-475c-ab8f-4e2e407a830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problematic scene: 20200701T114012_cis, 20200319T101935_cis\n"
     ]
    }
   ],
   "source": [
    "print(f\"problematic scene: 20200701T114012_cis, 20200319T101935_cis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9ff6e-5980-4f01-8c01-6830d1172ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
